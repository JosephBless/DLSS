{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "#If you are using Tensorflow 1.x\n",
    "from keras.optimizers import Adam\n",
    "#If you are using Tensorflow 2\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder containing dataset\n",
    "data_path = r'D:\\Downloads\\Dataset'\n",
    "\n",
    "#how many epochs to run the model\n",
    "epoch = 10\n",
    "\n",
    "#how many epochs between saving your model\n",
    "interval = 2\n",
    "\n",
    "#how many images to train at one time. If batch size is less than 9, alter the save_img function to plot less images\n",
    "batch = 10\n",
    "\n",
    "#if the data has pngs set this to True to remove alpha layer from images\n",
    "png = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset from local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "        data = []\n",
    "        small = []\n",
    "        paths = []\n",
    "        #get all files in this folder\n",
    "        for r, d, f in os.walk(data_path):\n",
    "            for file in f:\n",
    "                if '.jpg' in file or 'png' in file:\n",
    "                    paths.append(os.path.join(r, file))\n",
    "        #for each file add normal resolution and low resolution to arrays\n",
    "        for path in paths:\n",
    "            img = Image.open(path)\n",
    "            x = np.array(img.resize((64,64)))\n",
    "            y = np.array(img.resize((128,128)))\n",
    "            if(png):\n",
    "                x = x[...,:3]\n",
    "            data.append(y)\n",
    "            small.append(x)\n",
    "            \n",
    "        #reshaping data to be four dimension required for input to neural network\n",
    "        y_train = np.array(data)\n",
    "        y_train = y_train.reshape(len(data),128,128,3)\n",
    "        x_train = np.array(small)\n",
    "        x_train = x_train.reshape(len(small),64,64,3)\n",
    "        del data\n",
    "        del small\n",
    "        del paths\n",
    "        return y_train, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Shape of high resolution output image\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        # Shape of low resolution input image\n",
    "        self.latent_dim = (64,64,3)\n",
    "\n",
    "        #optimizer (learning rate and beta values)\n",
    "        optimizer = Adam(0.0001, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        generator = self.generator\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=self.latent_dim)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(128, input_shape=self.latent_dim, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(128, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(3, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=self.latent_dim)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "    \n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        Y_train, X_train = load_data()\n",
    "\n",
    "        # Rescale to be between 0 & 1\n",
    "        X_train = X_train / 255\n",
    "        Y_train = Y_train / 255\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Placeholder for loss function values\n",
    "        g_loss_epochs = np.zeros((epochs, 1))\n",
    "        d_loss_epochs = np.zeros((epochs, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, Y_train.shape[0], batch_size)\n",
    "            imgs = Y_train[idx]\n",
    "\n",
    "            # Generate super resolution images from the random batch of images\n",
    "            gen_imgs = self.generator.predict(X_train[idx])\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(X_train[idx], valid)\n",
    "            \n",
    "            #save loss history\n",
    "            g_loss_epochs[epoch] = g_loss\n",
    "            d_loss_epochs[epoch] = d_loss[0]\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch, X_train, idx)\n",
    "                \n",
    "        return g_loss_epochs, d_loss_epochs\n",
    "\n",
    "    def save_imgs(self, epoch, X_train, idx):\n",
    "        r, c = 3, 3\n",
    "        # Select 9 random images\n",
    "        index = np.random.randint(0, X_train.shape[0], 9)\n",
    "        images = X_train[idx]\n",
    "        # Super resolution the images\n",
    "        gen_imgs = self.generator.predict(images)\n",
    "        gen_imgs = np.array(gen_imgs) * 255\n",
    "        gen_imgs = gen_imgs.astype(int)\n",
    "        # Plot each image\n",
    "        fig=plt.figure(figsize=(20, 20))\n",
    "        for i in range(1, c*r+1):\n",
    "            img = gen_imgs[i-1]\n",
    "            fig.add_subplot(r, c, i)\n",
    "            plt.imshow(img)\n",
    "        fig.savefig(\"epoch_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "        # save model to .h5 file\n",
    "        self.generator.save(\"generator\" + str(epoch) + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model and View Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 273,601\n",
      "Trainable params: 273,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 128, 3)       3459      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 597,379\n",
      "Trainable params: 597,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = SRGAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.721709, acc.: 10.00%] [G loss: 0.689763]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 0.678665, acc.: 45.00%] [G loss: 0.672411]\n",
      "2 [D loss: 0.648853, acc.: 50.00%] [G loss: 0.638992]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [D loss: 0.654325, acc.: 50.00%] [G loss: 0.559246]\n",
      "4 [D loss: 0.703426, acc.: 50.00%] [G loss: 0.501717]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [D loss: 0.833334, acc.: 50.00%] [G loss: 0.463592]\n",
      "6 [D loss: 0.834711, acc.: 50.00%] [G loss: 0.521292]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [D loss: 0.741456, acc.: 50.00%] [G loss: 0.823451]\n",
      "8 [D loss: 0.657717, acc.: 65.00%] [G loss: 1.017002]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [D loss: 0.673446, acc.: 50.00%] [G loss: 1.125451]\n"
     ]
    }
   ],
   "source": [
    "g_loss, d_loss = gan.train(epochs=epoch, batch_size=batch, save_interval=interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hVVfbw8e9KIySElkILEEIPHULvRRCl2FABUWyIiqhYx5lRdObV0Z8VdVQGEQuKioqo2OggUkJVOoQAgUASSgghPfv949xADCGEkJuTe+/6PE+e3Hvqykly1t377CLGGJRSSnkuL7sDUEopZS9NBEop5eE0ESillIfTRKCUUh5OE4FSSnk4TQRKKeXhNBEopZSH00Sg3J6I3Cwia0QkTUQSHa/vExEptN1UETEi0qXQ8vGO5Y8VWh4vIv0ucM5ZIvLvMv9hlHICTQTKrYnII8AbwP8BtYFawESgJ+BXYDsBxgHHgduKONRx4AkRqersmJUqb5oIlNsSkWrAc8B9xpi5xphUY9lojBlrjMkssHlvoC7wIHCziPgVOtx24Hfg4TKI624R2SMix0VkvojUdSwXEXnNUWpJEZEtItLase4qEdkmIqkickhEHr3cOJTKp4lAubPuQCXg2xJsexvwHfC54/2wIrb5J/CwiNQsbUAiMgB4AbgRqAPsB+Y4Vg8G+gDNgOrATcAxx7r3gXuMMUFAa2BxaWNQqjBNBMqdhQDJxpic/AUiskpETopIuoj0cSwLAEYBnxpjsoG5FFE9ZIzZBPwCPHEZMY0FZhpjNjhKJH8DuotIBJANBAEtADHGbDfGJDj2ywaiRKSqMeaEMWbDZcSg1F9oIlDu7BgQIiI++QuMMT2MMdUd6/L//q8FcoAFjvezgaEiElrEMZ8G7hWR2qWMqS5WKSA/ntOOWOoZYxYDbwFvA0dFZHqBZxLXA1cB+0VkmYh0L+X5lTqPJgLlzn4HMoGRF9nuNqAKcEBEjgBfAr7A6MIbGmN2AF8DT5UypsNAw/w3IhIIBAOHHMefZozpBLTCqiJ6zLF8nTFmJBAGzAO+KOX5lTqPz8U3Uco1GWNOisizwH8drYJ+As4AbYFAABGpBwwEhgJbCuz+EFaCmFbEoZ91bCtFrCvIW0T8C7zPAz4F5ojIp1gPoJ8H1hhj4kSkM9aHsw1AGpAB5DoeXI8CvjfGpIjIKSC3hJdBqYvSEoFya8aYl4ApwONAInAUeA+rnn8VVpPRTcaYX4wxR/K/sBJA2/xWO4WOuQ/4GEcyKcaTQHqBr8XGmEVYD52/AhKAxsDNju2rAv8DTmBVHx0DXnasGwfEOZLAROCWS7wUSl2Q6MQ0Sinl2bREoJRSHk4TgVJKeThNBEop5eE0ESillIdzueajISEhJiIiwu4wlFLKpaxfvz7ZGFNUJ0nXSwQRERHExMTYHYZSSrkUEdl/oXVaNaSUUh5OE4FSSnk4TQRKKeXhXO4ZQVGys7OJj48nIyPD7lBUIf7+/oSHh+Pr62t3KEqpC3CLRBAfH09QUBAREREUmoZW2cgYw7Fjx4iPj6dRo0Z2h6OUugC3qBrKyMggODhYk0AFIyIEBwdrSU2pCs4tEgGgSaCC0t+LUhWf2yQCpZRyV8YY3li4m+0Jp5xyfE0EZejo0aOMGTOGyMhIOnXqRPfu3fnmm29siWXp0qWsWrXKlnMrpcpOXp7h2e+28drCXczffNgp59BEUEaMMVxzzTX06dOH2NhY1q9fz5w5c4iPj3faOXNyci64rjSJoLjjKaXKX26e4W9f/8GsVXHc1asRjw9p7pTzaCIoI4sXL8bPz4+JEyeeXdawYUMeeOABcnNzeeyxx+jcuTNt27blvffeA6ybdb9+/bjhhhto0aIFY8eOJX+ioPXr19O3b186derEkCFDSEhIAKBfv3489dRT9O3blzfeeIPvvvuOrl270qFDBwYNGsTRo0eJi4vj3Xff5bXXXqN9+/asWLGC/fv3M3DgQNq2bcvAgQM5cOAAAOPHj2fKlCn079+fJ554opyvmlLqQrJz85jyxSY+jznI5AFN+PvVLZ32zM0tmo8W9Ox3W9l2uGzr0aLqVuWZ4a2K3Wbr1q107NixyHXvv/8+1apVY926dWRmZtKzZ08GDx4MwMaNG9m6dSt169alZ8+e/Pbbb3Tt2pUHHniAb7/9ltDQUD7//HP+/ve/M3PmTABOnjzJsmXLADhx4gSrV69GRJgxYwYvvfQSr7zyChMnTqRKlSo8+uijAAwfPpxbb72V2267jZkzZzJ58mTmzZsHwK5du1i4cCHe3t5lcr2UUpcnMyeXBz7dyC/bjvL4lc25r18Tp57P7RJBRXH//fezcuVK/Pz8aNiwIVu2bGHu3LkApKSksHv3bvz8/OjSpQvh4eEAtG/fnri4OKpXr86ff/7JFVdcAUBubi516tQ5e+ybbrrp7Ov4+HhuuukmEhISyMrKumB7/d9//52vv/4agHHjxvH444+fXTdq1ChNAkpVEOlZuUz8ZD3LdiUxdXgU43s6vw+O0xKBiMwEhgGJxpjzJgAXkRbAB0BH4O/GmJcLb1MaF/vk7iytWrXiq6++Ovv+7bffJjk5mejoaBo0aMCbb77JkCFD/rLP0qVLqVSp0tn33t7e5OTkYIyhVatW/P7770WeKzDw3JzpDzzwAFOmTGHEiBEsXbqUqVOnlijegkXMgsdTStnndGYOd324jjX7jvPi9W24qXODcjmvM58RzAKuLGb9cWAyUCYJwG4DBgwgIyODd9555+yyM2fOADBkyBDeeecdsrOzAasqJi0t7YLHat68OUlJSWcTQXZ2Nlu3bi1y25SUFOrVqwfAhx9+eHZ5UFAQqampZ9/36NGDOXPmADB79mx69epVmh9TKeUkKenZjHt/DeviTvD6Te3LLQmAExOBMWY51s3+QusTjTHrgGxnxVCeRIR58+axbNkyGjVqRJcuXbjtttt48cUXueuuu4iKiqJjx460bt2ae+65p9gWOn5+fsydO5cnnniCdu3a0b59+wu2AJo6dSqjRo2id+/ehISEnF0+fPhwvvnmm7MPi6dNm8YHH3xA27Zt+fjjj3njjTfK/BoopUrneFoWY/63mj8PpfD2mI6MbF+vXM8v+a1UnHJwkQjg+6KqhgpsMxU4XVzVkIhMACYANGjQoNP+/X+dX2H79u20bNmyDCJWzqC/H6UuLPFUBmNnrOHA8TO8N64T/ZqHOeU8IrLeGBNd1DqXaD5qjJlujIk2xkSHhhY505pSSrmcQyfTufG93zl0Mp1Zt3dxWhK4GG01pJRSNohLTmPsjDWcysjm4zu70qlhDdti0USglFLlbPfRVMbOWEN2bh6f3d2N1vWq2RqPM5uPfgb0A0JEJB54BvAFMMa8KyK1gRigKpAnIg8BUcYY54yqpJRSFcDWwymMe38t3l7C5/d0p1mtILtDcl4iMMaMvsj6I0C4s86vlFIVzcYDJ7ht5lqqVPJh9t3daBRSMfrwaNWQUkqVg9Wxx7hz1jpCgiox+66uhNcIsDuks1yi1ZAr8Pb2pn379rRq1Yp27drx6quvkpeXB0BMTAyTJ0++7HO8++67fPTRR5e0T48ePUp9vlmzZnH4sHOGvVXKkyzblcT4D9ZSp3plvrine4VKAqAlgjJTuXJlNm3aBEBiYiJjxowhJSWFZ599lujoaKKji2y+W2I5OTl/Gdm0pC5nToJZs2bRunVr6tatW+J9cnNzddwipQr4ZesRJn26kSZhVfj4zi4EV6l08Z3KmZYInCAsLIzp06fz1ltvYYxh6dKlDBs2DIBly5bRvn172rdvT4cOHc4OA/HSSy/Rpk0b2rVrx5NPPgmcP+T01KlTefnll8+ue/jhh+nTpw8tW7Zk3bp1XHfddTRt2pR//OMfZ2OpUqUKUPyQ18899xydO3emdevWTJgwAWMMc+fOJSYmhrFjx9K+fXvS09NZtGgRHTp0oE2bNtxxxx1kZmYCEBERwXPPPUevXr348ssvy+ciK+UC5m8+zL2zNxBVtyqf3d2tQiYBcMcSwY9PwpE/yvaYtdvA0P9c0i6RkZHk5eWRmJj4l+Uvv/wyb7/9Nj179uT06dP4+/vz448/Mm/ePNasWUNAQADHj58bmaPgkNOFB5Tz8/Nj+fLlvPHGG4wcOZL169dTs2ZNGjduzMMPP0xwcPBfti9qyOtevXoxadIknn76acAamfT777/nhhtu4K233uLll18mOjqajIwMxo8fz6JFi2jWrBm33nor77zzDg899BAA/v7+rFy58pKukVLu7It1B3ni6y10jqjJzPGdqVKp4t5utUTgREUN39GzZ0+mTJnCtGnTOHnyJD4+PixcuJDbb7+dgACr3rBmzZpnty845HRhI0aMAKBNmza0atWKOnXqUKlSJSIjIzl48OB52+cPee3l5XV2yGuAJUuW0LVrV9q0acPixYuLHOBu586dNGrUiGbNmgFw2223sXz58hLFqZSn+XBVHI9/tYVeTUL48PYuFToJgDuWCC7xk7uzxMbG4u3tTVhYGNu3bz+7/Mknn+Tqq69mwYIFdOvWjYULF2KMueDMQ8UNEZ0/hLWXl9dfhrP28vIqclC7ooa8zsjI4L777iMmJob69eszdepUMjIyztv3YmNS6VDWSlneXbaX//y4gyuiavHWmA5U8qn4z8y0ROAESUlJTJw4kUmTJp13g9+7dy9t2rThiSeeIDo6mh07djB48GBmzpx5dtjqglVDzpZ/0w8JCeH06dNnJ8+Bvw5l3aJFC+Li4tizZw8AH3/8MX379i23OJWq6IwxvPbrLv7z4w6Gt6vLf8d2dIkkAO5YIrBJeno67du3Jzs7Gx8fH8aNG8eUKVPO2+71119nyZIleHt7ExUVxdChQ6lUqRKbNm0iOjoaPz8/rrrqKp5//vlyibt69ercfffdtGnThoiICDp37nx23fjx45k4cSKVK1fm999/54MPPmDUqFHk5OTQuXPnUrViUsodGWN44ccdTF8ey6hO4fzn+rZ4ezlnfmFncOow1M4QHR1tYmJi/rJMhzmu2PT3o9xZXp7h6fl/8snqA9zavSFTh7fCqwImgeKGodYSgVJKlVJunuGJr7Ywd3089/SN5MkrW1zweV9FpolAKaVKITs3j4c+38QPWxJ4eFAzJg9s4pJJANwoERTX8kbZx9WqHpUqiYzsXCZ9uoGF2xN56qoWTOjT2O6QLotbtBry9/fn2LFjetOpYIwxHDt2DH9/f7tDUarMpGflcvdHMSzcnsi/RrZy+SQAblIiCA8PJz4+nqSkJLtDUYX4+/sTHq6jjSv3kJqRzZ2zYojZf5z/u6Eto6Lr2x1SmXCLRODr60ujRo3sDkMp5cZOnsnitplr2Xr4FG/c3IHh7Uo+GGNF5xaJQCmlnCn5dCa3zFhDbFIa79zSiSuiatkdUpnSRKCUUsU4kpLB2BmrOXQynffHR9O7aajdIZU5TQRKKXUBObl53DFrHUdSMvjw9i50jQy++E4uSBOBUkpdwGdrD7At4RT/HdvRbZMAuEnzUaWUKmsn0rJ4+Zdd9GgczNDWte0Ox6mclghEZKaIJIrInxdYLyIyTUT2iMgWEenorFiUUupSvfLrTk5n5vDM8FZu31nVmSWCWcCVxawfCjR1fE0A3nFiLEopVWLbDp/i0zUHGNetIc1rB9kdjtM5LREYY5YDxQ2sPxL4yFhWA9VFpI6z4lFKqZIwxjD1u61Uq+zLw4Oa2R1OubDzGUE9oOB8ivGOZecRkQkiEiMiMdp7WCnlTN9vSWDtvuM8NqQF1QJ87Q6nXNiZCIqqdCtysCBjzHRjTLQxJjo01P3a8CqlKoYzWTk8v2A7repW5abO7jF8REnY2Xw0Hih4pcOBwzbFopRSvLt0LwkpGUwb3cGlZhi7XHaWCOYDtzpaD3UDUowxCTbGo5TyYAePn+Hd5bGMbF+XzhE17Q6nXDmtRCAinwH9gBARiQeeAXwBjDHvAguAq4A9wBngdmfFopRSF/PvH7bh4yX8bajnTavqtERgjBl9kfUGuN9Z51dKqZJasTuJn7ce5bEhzaldzfPmz9CexUopj5adm8ez322jYXAAd/byzOHsNREopTzax7/vZ0/iaf5xdRT+vt52h2MLTQRKKY+VfDqT1xbuok+zUAa1DLM7HNtoIlBKeayXf95JelYuTw+LcvvxhIqjiUAp5ZH+iE/h85iD3N4zgiZhVewOx1aaCJRSHscYwzPz/yQ40I8HBja1OxzbaSJQSnmceZsOseHASR6/sgVV/T1jPKHiaCJQSnmU05k5vLBgB+3Cq3FDx3C7w6kQdKpKpZRHeWvxHhJTM3lvXCe8PGg8oeJoiUAp5TH2Jacxc+U+bugUTocGNewOp8LQRKCU8hj//n4bfj5ePH5lc7tDqVA0ESilPMKSHYks2pHI5IFNCAvyvPGEiqOJQCnl9rJy8vjX99uIDAlkfA/PHE+oOJoIlFJub9aqfcQmp/H08Cj8fPS2V5heEaWUW0s8lcEbC3czsEUY/Zp77nhCxdFEoJRyay/+tJPsXMM/h0XZHUqFpYlAKeW2Nh44wVcb4rmzdyMiQgLtDqfC0kSglHJLeXmGqfO3UqtqJSb1b2J3OBWaJgKllFuauyGezfEp/G1oSwIr6SAKxdFEoJRyO6cysnnppx10aliDke3r2h1OhefURCAiV4rIThHZIyJPFrG+oYgsEpEtIrJURHQEKKXUZZu2cDfH0rKYOryVR084U1JOSwQi4g28DQwFooDRIlL4sf3LwEfGmLbAc8ALzopHKeUZ9iSeZtaqOG7uXJ824dXsDsclOLNE0AXYY4yJNcZkAXOAkYW2iQIWOV4vKWK9UkqVmDGGZ7/bSmU/bx4drOMJlZQzE0E94GCB9/GOZQVtBq53vL4WCBKRYCfGpJRyYwu3J7JidzIPD2pGcJVKdofjMpyZCIqqmDOF3j8K9BWRjUBf4BCQc96BRCaISIyIxCQlJZV9pEopl5eRncu/vt9G07AqjOve0O5wXIozE0E8UL/A+3DgcMENjDGHjTHXGWM6AH93LEspfCBjzHRjTLQxJjo0NNSJISulXNX7K/dx4PgZnhneCl9vbRB5KZx5tdYBTUWkkYj4ATcD8wtuICIhIpIfw9+AmU6MRynlphJS0nlr8R6ubFWbXk1D7A7H5TgtERhjcoBJwM/AduALY8xWEXlOREY4NusH7BSRXUAt4P85Kx6llPv6z487yDWGv1/d0u5QXJJTu9sZYxYACwote7rA67nAXGfGoJRyb+vijvPtpsNMHtCE+jUD7A7HJWlFmlLKZeU6xhOqW82fe/vpeEKlpYlAKeWyPl93kK2HT/HU1S2p7OdtdzguSxOBUsolpZzJ5v9+3kHXRjW5uk0du8NxaZoIlFIu6bWFu0hJz2bqCB1P6HJpIlBKuZydR1L5ePV+xnZtSMs6Ve0Ox+VpIlBKuZT88YSC/H2YckUzu8NxC5oIlFIu5ac/j7Bq7zEeGdycGoF+dofjFjQRKKVcRkZ2Lv/+YTstagcxpksDu8NxGzp/m1LKZby3LJZDJ9OZM6Eb3l76gLisaIlAKeUS4k+c4b9L9zCsbR26Repo9WVJE4FSyiW8sGAHIvDUVTqeUFnTRKCUqvBW7U3mhz8SuL9fE+pWr2x3OG5HE4FSqkLLyc3jue+2EV6jMnf3ibQ7HLekD4uVqiiMgcMbIP0E5OWByYW8XMf3nCKW5X/PK7BN4WVFbJuXc4H9C2wbGAL9/w4BNe2+Kny69gA7jqTy7i2d8PfV8YScQROBUhXFshdh6Qtlf1zxBi/v87+ft8zr3PsTcbBnEYyeA2Etyj6mEjqelsUrv+yiV5MQhrSqZVsc7k4TgVIVwcbZVhJoexNE3+m4OXsVuEn7FLGs4HfHci+f82/upXFwLcwZCzMGwQ3vQ7MhZfvzltArv+zkdGYOzwyP0vGEnEgTgVJ227sEvpsMjfrCiLfApwL0lq3fBSYsgc9Gw6c3waCp0PNBKMeb8dbDKXy29gC39Yigaa2gcjuvJ9KHxUrZ6ehW+OJWCGkGN31cMZJAvmrhcMdPEDUSFj4D30yE7IxyO/20RbupVtmXhwbpeELOVqJEICKB+ZPMi0gzERkhIr7ODU0pN3cqAWbfCH6BMPZL8K9md0Tn8wuEUbOsB8db5sCsqyH1iNNPe+x0Jou2J3JDp3CqVdZbjbOVtESwHPAXkXrAIuB2YJazglLK7WWmwqejIOMkjPnC+vRdUYlA38fhxo8hcRtM7w+HNjj1lPM3HyYnz3B9pwp8XdxISROBGGPOANcBbxpjrgWinBeWUm4sNwe+HA9Ht8GoD6FOW7sjKpmoEXDnL9YD6Q+Gwh9znXaquevjaVOvGi1q61wD5aHEiUBEugNjgR8cyy76oFlErhSRnSKyR0SeLGJ9AxFZIiIbRWSLiFxV8tCVckHGwIJHYM9CGPYqNB1kd0SXpnYbuHsx1O0IX90Ji56z+iGUoW2HT7H18Clu0NJAuSlpIngI+BvwjTFmq4hEAkuK20FEvIG3gaFYpYfRIlK4FPEP4AtjTAfgZuC/lxK8Ui5n5Wuwfhb0mgKdxtsdTelUCYVbv4WOt8KKV+DzW6yqrjLy1YZ4fL2FEe3qltkxVfFKlAiMMcuMMSOMMS86HhonG2MmX2S3LsAeY0ysMSYLmAOMLHxoIL/sVw04fAmxK+VatnwJi56F1jfAgH/aHc3l8fGD4dPgyhdh14/w/mCrE9plys7NY97GQwxqWUsnnSlHJW019KmIVBWRQGAbsFNEHrvIbvWAgwXexzuWFTQVuEVE4oEFwAMXOP8EEYkRkZikpKSShKxUxRL3G3x7HzTsBdf8t/QdvSoSEeg2EW75Ck4dsh4ix628rEMu3ZnEsbQsrRYqZyX9a4wyxpwCrsG6YTcAxl1kn6J6nphC70cDs4wx4cBVwMf5zVT/spMx040x0caY6NDQ0BKGrFQFkbQL5oyBGhFw8yfgU8nuiMpW4wFw12IICIaPRkLMB6U+1Nz1BwmpUok+zfT/vDyVNBH4OvoNXAN8a4zJ5vybemHxQP0C78M5v+rnTuALAGPM74A/EFLCmJSq+E4nwuzrwdvX6itQuYbdETlHSBO4exFE9oPvH4IFj0Fu9iUdIr/vwLUd6uLr7QYlJhdS0qv9HhAHBALLRaQhcOoi+6wDmopIIxHxw3oYPL/QNgeAgQAi0hIrEWjdj3IPWWnW8AxpyTDmc6tE4M78q1l9IrpPgrXT4ZPr4MzxEu+ufQfsU9KHxdOMMfWMMVcZy36g/0X2yQEmAT8D27FaB20VkedEZIRjs0eAu0VkM/AZMN4Yc7GShlIVX14ufHUXJGyC69+Hep3sjqh8eHnDkP8H17wDB1bD/wZA4o4S7ap9B+xTokHnRKQa8AzQx7FoGfAckFLcfsaYBVjPFAoue7rA621Az0uIV6mKzxj46UnYuQCG/h+08MDuMe3HQHCTEo9gmt93YOpw7adqh5JWDc0EUoEbHV+ngNI/EVLKnf3+tlU10n0SdJ1gdzT2yR/BNDjSqiJb+bqVJItwtu9A+8INC1V5KGkiaGyMecbRJyDWGPMsoHPGKVXYtm/hl39AyxFwxb/sjsZ+1cLh9p+g1TUXHME0v+/AwBa1qKl9B2xR0kSQLiK98t+ISE8g3TkhKeWiDq6FrydAeGe4brp79BUoC34BcMMHFxzBVPsO2K+kf6kTgbdFJE5E4oC3gHucFpVSrubYXvjsZqha15re0bey3RFVLMWMYGr1HfCjb3PtO2CXkrYa2myMaQe0Bdo6xgYa4NTIlHIVacdg9g1W/ffYuRAYbHdEFVehEUxPx3zO4h2JXNO+nvYdsNElXXljzClHD2OAKU6IRynXkp0Oc0ZDyiGrJBDc2O6IKr4CI5hW+X4CD8ocru+oA8zZ6XJSsM4krTxbXp718PPgWuuZQIOudkfkOhwjmP5caTCTfL6l5bL7ynQEU3VpLicRaMcv5dkWPg3b5sHgf1mtYtQl2Z6UwT0pt7G6+ROw66cyG8FUXbpiE4GIpIrIqSK+UgEtyynPtfZ/sOpN6Hy31V9AXbKv1sfj6+1FsxGPwi1zy2wEU3Xpik0ExpggY0zVIr6CjDEl6pWslNvZ+SP8+Dg0GwpDX7RaxKhLkp2bx7xNBfoOlOEIpurS6WN6pS7FoQ0w9w6o084aNsHL2+6IXNKynUkkny7Ud6AMRjBVpaOJQKmSOrHfGiohMMQaZdMv0O6IXNbc9fFF9x0oPILpx9dC6lF7gvQgmgiUKon0EzB7FORmWn0FqoTZHZHLOp6WxaIdRy/cd+DsCKbvQnwMvNsT9iwq/0A9iCYCpS4mJxPm3AIn9sHNn0Joc7sjcmnzNx0iO7cE8w60H20NWhcQYs1tsHCqVhU5iSYCpYpjDHx7P+xfCSP/CxG9Lr6PKtbcDfG0qluVlnVKMO9AWEur81nH22Dla9Y4RScPXnw/dUk0EShVnMX/gj++hAH/hLaj7I7G5W1POMWfh05d2gBzfgEwYpo1wc/RbfBuL9jxg/OC9ECekwjy8qwivlIltX4WrHgFOt4KvR+xOxq3YPUdEEaWZt6BNjfAPcugRkOYMwZ+fEL/p8uI5ySCuOXwSgvrjydhi93RqIpu90L4fgo0GQRXv6p9BcpAft+BAS3CSj/vQHBjuPNX6HovrHkX3r/CGvlVXRbPSQSVa0BkX4iZCe/1toqXa967pMm1lYdI2AJf3ga1omDULPD2tTsit7B8V37fgfqXdyCfSjD0P3DzZ1aT3vf6wh9zyyZID+U5iaBOO+uf+pGd1jyy4mX1Dn2lOXxxG+z+1ZpwXHm2lHj49EZHe/YvoVKQ3RG5jbnr4wkO9KNfWc070OIqmLgSarWCr+6EbydB1pmyObaH8bxhIgJqWvPIdp0AR/6AjbNhy+fW4GFBdaDdzdD+FquXo/IsGSkw+0bISoM7foKqdeyOyG2cSMti4faj3No9omznHaheH8b/AEufhxWvQvw66wNfWMuyO4cHcGqJQESuFJGdIrJHRJ4sYv1rIrLJ8bVLRE46M57z1G5jFTEf2WnNnFS7Lfz2BrzVCd4fApxO0k8AABswSURBVBs+0qFxPUVutlUyTN4JN35kfcpUZWb+5sNk5xrnTEfp7QMDn4ZxX8OZY9bAdes/tJr+qhIR46SLJSLewC7gCiAeWAeMNsZsu8D2DwAdjDF3FHfc6OhoExMTU9bhnpN6BDbPgY2fwLHd4BsAUddAh1ugYQ99aOiO0k9a1YRbPrf6CnQYa3dEbmf4myvJM4YfJvd27olSj8LXd8O+ZdD6ehj2OviXoL+CBxCR9caY6KLWObNE0AXYY4yJNcZkAXOAkcVsPxr4zInxlExQbej1EExaZ7VOaDMKtn8Hs66CaR1g2f9Z9cjK9SXvhh8egVejrCTQ7ylNAk6w48gp/jiUUj6T0wfVgnHfWP0+ts6D9/rA4Y3OP6+Lc2YiqAcU7AIY71h2HhFpCDQCFl9g/QQRiRGRmKSkpDIPtEgiUL+L1ZHl0Z1w7XtQLRyW/Btea20NhvXHXMjOKJ94VNnIy7Oahn5yPbwVbVX/tboG7lkO/Z6wOzq3dFl9B0rDyxv6PGo9O8jNghlXwOp3tKqoGM58WFxUHcqFfhM3A3ONMUU22zHGTAemg1U1VDbhXQK/QOshcrubrRmUNn1qfX11p9W6pM0oaD8W6nbQqqOKKvM0bP7MajJ8bDdUqQX9/w6dbremTVROkZ2bxzcbD19e34HSatjdalU07z746UnYtxxGvm01GFF/4cxEEA8UbDAcDhy+wLY3A/c7MRbiT5xh1Z5jRIYG0ji0CjVK+0dZIwL6PwV9n7Q6qW38xPpaNwPCoqxnCW0dQxUr+52Is2YT2/AxZKZA3Y5w3f+s5z4+5Xxj8kBW34FMru9YDtVCRQmoCaM/s0oEvz4N7/a25pFo0M2eeCooZz4s9sF6WDwQOIT1sHiMMWZroe2aAz8DjUwJgintw+Kv1sfzyJebz76vEeBLZGgVIkMCiQytQuNQ63vD4IBLb96WfhK2fm0lhEPrwcsHml1pJYUmV1itGlT5MQb2/2b98+9cAAhEjYRu90J4Zy21laN7P1nP2n3HWf3UwLJtNloahzbA3NutQesG/B16PgxentOVqriHxU5LBI4TXwW8DngDM40x/09EngNijDHzHdtMBfyNMec1Ly1KaRNBTm4e8SfSiU0+TWxSGnuT0tibZL1OPn1uvBJvL6FBzYCziaFgoqgZ6Idc7CaSuB02zbZaHqUlQWAYtLvJ6psQ1uKS41aXIDvDGiBuzXtw9A+oXBM6jYfOd0G1cqqfVmedSMuiy/MLGdctgqeHR9kdjiUjBb57yPrgFtkfrpvuMXNL2JYInMEZzUdT0rPZl5zG3sTTZxNFbFIa+5LTyMrNO7tdtcq+RIYGEhlShcZhju+hgTQIDqCST6EpC3Ozrd7Km2bDrp8gLwfqRVutUlpfbz1bUGXjVIJVNbf+A6sdeVgUdJ0IbW8E38p2R+exPlwVxzPzt7Jgcm+i6lagJpzGwIYPrXHHKlW1kkHj/nZH5XSaCEopN89w6EQ6e88mh9NnSxGJqedKEV4C9WsG0LhACSL/WURIFT8kLdlqnrhpNiRus6qOwjtbc7M26gvh0TqeTWnEx1jVP9vmWcODNB9qJYBGfbT6pwIY/uZKcvMMCx50ct+B0jq6Fb68HZJ3WaPL9vubW1fjaiJwgtQMRyki6VwJYm/SafYlp5GZc64UEeTvY1UthQQSGRJAR584olKWUe3IKiRhE5g88A2EiJ5WUojsC2GtPKru8pLkZsO2b60EcCgG/IKg4zjocjfUjLQ7OuWw80gqQ15fztPDorijVyO7w7mwrDSrM+HGT6BBd7h+htVMvKJIPwHH91mz4x2PhXqdoPGAUh2quETgvunPyYL8fWkbXp224dX/sjwvz3DoZDqxyVYJIj9BrNp7jK83HnJs1YOGwYMY2safEdVjaX5mA95xy2H3L9bqgBDrU21kPysx1Igox5+sgkpLtqp+1r0PqQnWTX/oS9B+jA4MVwF9tSEeHy9hZPu6dodSPL9Aq0lpo37w/UPWqMTXvGOVLsuDMXA68dyN/rjje/779BN/3b7Xw6VOBMXREkE5SsvMYV9yGhsPnmTJjkR+25NMZk4egX7e9GoawrCGhr5+26l6+Deri3xqgrVj9YbnkkKjvp7VNPXIn7DmHdjypTVxfGR/q/VPkyu01FRB5eTm0e2FxXRsUJ3ptxb5AbRiOrYXvhwPR7ZAt/tg0LNl08Q4LxdOHTr/Jn88zvqenXZuW/GCavWhZiPrw07NSKjheF0jwpqtrZS0aqiCSs/KZdXeZBbvSGTxjkQSUqxeym3Dq9G/WShX1TlF07QNeMUth30rrHbwALXaWEkhsp9VnK1UxbafwSnycmHnj9bEI3ErwKey1Zmv60RteeUCFu84yh2zYpg+rhODW9W2O5xLk5MJv/wT1r4HddrDqA9KVuWYkwUnDxT9yf5EnNXDOZ+3n3VTL3iTz7/xV6vvtP4tmghcgDGGHUdSzyaFDQdOYAyEBlWif/NQBjarSe+gwwQcXGGVFg6ssT4he/lAeJdzpQVXfvCcftKqq107HU7uh6rhVt1/x1u1N6gLuW/2etbEVpC+A6W1/Tv49n5rSJLhr1vTZGalWTf18z7Zx1rjj5lzzwbxq+K4yTc6d5PPv+lXrWsNg1HONBG4oONpWSzblcii7Yks25VEakYOvt5Ct8hg+jcPY1DTIBqc/sNKCrFL4fAmwFh/gA17OB4897OaUlb0KpTkPdan/02fWsXkBt2tT/8thrl1Kw53dCIti67PL+KWbg0rTt+B0jp5AObeCfFrITDU6hdUUOWa59/k898Hhla4lmuaCFxcdm4e6/efOFta2JN4GoDI0EAGtgijf4swOtcSfA/8di4xHNtj7RwQcq60ENnPmvi7LOXmWDfvzNPWJ6asVMf3/GX5yx2vz27n2Db9pFUn6+1n9a/oeo81ZpNySR/9HsfT31bAvgOllZsNq6bBsVioGVHgpt/Imv7WhWgicDMHjp1h8Y6jLNqRyJrY42Tl5hFUyYc+zUIZ0CKMfs1DCc5NPpcUYpfB6SPWzjUiziWF4MYFbsqnL3IzL3ADz0w9t0/OJYy+6lPZep7hF2iVXPwcr+t3sQZ/C6pV9hdLlasRb60kJ7cC9x3wYJoI3FhaZg4r9ySzxFFaSEzNRATa169+trQQVTsISd51LjHErYTMU8Uf2MvXcdMueON2fC/qZn522/x1gVazzoL72lAvqsqPy/Qd8FCaCDxEXp5hW8IpFm1PZPGOo2yOt1oZ1anmT7/mYQxsEUbPJiFU9jaQsMlqnpp/8y58c9eROdUlen7Bdmau3MeapwYSXKWS3eGoQrRDmYfw8hJa16tG63rVeHBQUxJTM1i6M4klOxKZv+kQn609gJ+PFz0aBzOgRRhXtmpNWFV/u8NWbiAnN4+vNxyif4swTQIuSBOBGwsL8ufG6PrcGF2frJw81sUdP1taePrbrbz0006mjmjF9R3rXXxUVaWKsXy3Ne9AuUxHqcqcJgIP4efjRc8mIfRsEsLTw6PYdTSVf8z7k0e/3MziHUd5/to2VA/Q6iBVOnPXx1Mz0I/+zT1jSGd3U8EbmCtnaVYriM/u7sbjVzbnl61HGfL6clbuTrY7LOWCTqRlsXBbIiPb18XPR28prkh/ax7M20u4r18T5t3fkyqVfLjl/TX86/ttZGQXOXW0UkX6bsthsnLztFrIhWkiULSuV43vH+jNuG4NeX/lPq55+zd2HLlI81KlHL5aH0/LOlVpVVcnW3JVmggUAJX9vPnXNa35YHxnkk9nMuLN35ixIpa8PNdqXqzK166jqWyOT9HSgIvTRKD+on+LMH56qA99moXw7x+2c+vMtRxJuYTew8qjfLXeReYdUMXSRKDOE1KlEv+7NZrnr23D+v0nGPL6chb8kWB3WKqCycnN4+uNVt+BEO074NI0EagiiQhjujbgh8m9iAgO4L7ZG3j0y82kZmTbHZqqIFbsTiYpVfsOuAOnJgIRuVJEdorIHhF58gLb3Cgi20Rkq4h86sx41KWLDK3C3Ht7MHlAE77eEM9V01YQE3fc7rBUBaB9B9yH0xKBiHgDbwNDgShgtIhEFdqmKfA3oKcxphXwkLPiUaXn6+3FlMHN+XJidwBufO93XvllJ9m5eRfZU7mrk2ey+HXbUe074Cac+RvsAuwxxsQaY7KAOcDIQtvcDbxtjDkBYIxJdGI86jJ1aliTBZN7c13HcN5cvIcb3llFbNJpu8NSNvhus/YdcCfOTAT1gIMF3sc7lhXUDGgmIr+JyGoRubKoA4nIBBGJEZGYpKSkojZR5STI35eXR7Xjv2M7EnfsDFdPW8mnaw7gaqPYqsszd308LWoHad8BN+HMRFDUKGaF7xY+QFOgHzAamCEi1c/byZjpxphoY0x0aGhomQeqLt1Vberw80N96NSwBk998wd3f7SeY6cz7Q5LlQPtO+B+nJkI4oH6Bd6HA4eL2OZbY0y2MWYfsBMrMSgXULuaPx/d0YV/Doti+e4khry+giU7tHbP3eX3HbimQ+ECvnJVzkwE64CmItJIRPyAm4H5hbaZB/QHEJEQrKqiWCfGpMqYl5dwZ69GzJ/Uk5Aqftw+ax3/nPcn6Vk6XpE7yu870K+59h1wJ05LBMaYHGAS8DOwHfjCGLNVRJ4TkRGOzX4GjonINmAJ8Jgx5pizYlLO06J2Vebd35O7ejXi49X7GfbmCv48lGJ3WKqMad8B96RTVaoy99ueZB75YjPJpzOZMrgZ9/RpjLeXTnzjDu6fvYFVe5NZ89QgbTbqYoqbqlJ/k6rM9WwSwk8P9WZwq1q89NNORv9vNfEnztgdlrpMKWeyHX0H6mkScDP621ROUT3Aj7fHdOSVUe3YdvgUQ19fwbyNh+wOS12G+TrvgNvSRKCcRkS4vlM4Pz7Ym+a1g3jo801M/mwjKWd0vCJXdK7vQFW7Q1FlTBOBcrr6NQOYM6Ebjw5uxoI/Ehj6xnJ+36ttAlzJ7qOpbD54khs6hSOiz3vcjSYCVS58vL2YNKApX93bA39fb8bMWM0LC7aTmaPNTF3B3A3ad8CdaSJQ5apd/ep8P7kXo7s04L3lsVzz9iptZlrB5eTm8c0G7TvgzjQRqHIX4OfD89e2Ycat0SSeymDYmyu5b/Z6dh5JtTs0VYQVe5JJ1L4Dbs3H7gCU5xoUVYvFEf14f2UsM3+L48c/jzCsbV0eHNiUJmFV7A5POcxdH0+NAF8GtNB5B9yVlgiUraoF+DJlcHNWPN6fe/s2ZtH2owx+bRkPf76Jfclpdofn8VLOZPPrVu074O70N6sqhBqBfjx+ZQtWPN6fu3tH8uOfCQx6dRmPfrmZA8e0M5pdtO+AZ9BEoCqU4CqV+NtVLVn+eH/G94jgu82HGfDKUv729RbtnWwD7TvgGTQRqAopLMjfGt768f7c0q0hX60/RP+Xl/KPeX+QkJJud3geQfsOeA5NBKpCq1XVn6kjWrH0sX7c1Lk+n687SN+XljJ1/laOnsqwOzy3NndDPN5ewsj22nfA3WkiUC6hbvXK/PuaNix5tB/Xd6rHJ6v30+elJfzr+20kperMaGUtv+9A/+ahhAZp3wF3p4lAuZTwGgG8cF1bFj/Sj+Ht6vLBb/vo/dJiXliwXafKLEMrte+AR9FEoFxSg+AAXh7VjoVT+jK0dR2mr4il90tLeOmnHZxIy7I7PJd3ru9ALbtDUeVAE4FyaZGhVXjtpvb8+nAfBrasxTvL9tL7pSW8+stOUtJ1lNPSSDmTzS8674BH0d+ycgtNwoJ4c3QHfnqwD32ahTBt8R56vbiYaYt2k5qhCaGkYuKOc/dHMWTl5HF9R60W8hQ6VaVyS9sOn+L1hbv4ZdtRqlX2ZUKfSG7rEUGVSjqqSlE2HjjBawt3s3xXEiFV/HhoUDNu6dbQ7rBUGSpuqkpNBMqt/RGfwusLd7FoRyI1A/24p08k47o3JMBPEwLAn4dSePXXXSx2XJ+JfSO5pZteH3ekiUB5vE0HT/Lar7tY5vjEO7FvY27p1hB/X2+7Q7PF9oRTvParlpg8iW2JQESuBN4AvIEZxpj/FFo/Hvg/IH8y27eMMTOKO6YmAnU5YuKO89rCXfy25xihQZW4v19jbu7SwGMSwu6jqby+cDc//JFAUCUf7uodye29Iqjq72t3aMrJbEkEIuIN7AKuAOKBdcBoY8y2AtuMB6KNMZNKelxNBKosrI49xqu/7mLtvuPUrurP/QOacEPHcCr7uWdCiE06zRuLdjN/82ECfL25o1cj7uoVSbUATQCeorhE4MxyYBdgjzEm1hHEHGAksK3YvZQqB90ig/l8Qjd+33uMV37dxT/n/ckLC7YzsGUtrm5Th37NQ92ilLD/WBrTFu3hm43xVPLx5p4+jZnQJ5KagX52h6YqEGcmgnrAwQLv44GuRWx3vYj0wSo9PGyMOVh4AxGZAEwAaNCggRNCVZ5IROjRJITujYNZs+848zcf5qc/j/Dd5sME+nkzKMpKCn2auV5SiD9xhrcW7+HL9dZcw3f0bMTEfo11qklVJGdWDY0Chhhj7nK8Hwd0McY8UGCbYOC0MSZTRCYCNxpjBhR3XK0aUs6Uk5vH6tjjfL/lMD9tPcLJM9kEVfLhiqhaXN22Dr2ahlDJp+ImhYSUdN5esofP1x1EEMZ0bcB9/RoTVtXf7tCUzeyqGooH6hd4Hw4cLriBMeZYgbf/A150YjxKXZSPtxe9mobQq2kI/7qmNav2HuOHLVZJ4euNhwjy92FwVG2GtatDz8YhFabnbeKpDP67dC+frj2AMYYbo+szaUAT6lSrbHdoygU4s0Tgg1XdMxCrVdA6YIwxZmuBbeoYYxIcr68FnjDGdCvuuFoiUHbIysnjtz3JfL8lgV+2HSE1I4dqlX0Z0qoWV7etS4/Gwfh6l39SSD6dybtL9/Lx6v3k5BlGdQrn/v5NqF8zoNxjURWbLSUCY0yOiEwCfsZqPjrTGLNVRJ4DYowx84HJIjICyAGOA+OdFY9Sl8PPx4v+LcLo3yKMzJzWrNydzA9bEljwxxG+iImneoAvV7aqzbC2dekWWRMfJyeFE2lZvLc8lg9XxZGZk8u1HcKZPLAJDYMDnXpe5Z60Q5lSlyEjO5flu5L44Y8EFm47SlpWLjUD/biydW2GtalD18hgvL3KbnavlDPZzFgZy8yV+ziTncvwtnV5cFBTGodWKbNzKPekPYuVKgcZ2bks3ZnE91sOs2h7IunZuYRU8WNo6zpc3bYOnSNqljoppGZkM3NlHDNWxpKakcPVberw4KCmNKsVVMY/hXJXmgiUKmfpWbks2ZnID1sSWLTjKBnZeYQGVeKq1rUZ1q4unRrUwKsESSEtM4dZq+L434pYTp7JZnBULR4a1IwonUxeXSJNBErZ6ExWDou2W0lhyc5EMnPyqFW1Ele1qcOwtnXoUP/8pJCelcvHq+N4d1ksx9OyGNAijIcHNaNNeDWbfgrl6jQRKFVBnM7MYdH2o/ywJYGlu5LIysmjbjV/rmpjVR+1rFOVT9cc4L9L95J8OpPeTUN4+IpmdGxQw+7QlYvTRKBUBZSakc1CR1JYtiuJ7FyDn7cXWbl5dI8MZsrgZnSOqGl3mMpN2NWhTClVjCB/X67tEM61HcJJSc9m4bajrD9wgmFt69CjcYjd4SkPoolAqQqgWmVfru8UzvWddHpIVf4qRv94pZRSttFEoJRSHk4TgVJKeThNBEop5eE0ESillIfTRKCUUh5OE4FSSnk4TQRKKeXhXG6ICRFJAvaXcvcQILkMw3F1ej3+Sq/HOXot/sodrkdDY0xoUStcLhFcDhGJudBYG55Ir8df6fU4R6/FX7n79dCqIaWU8nCaCJRSysN5WiKYbncAFYxej7/S63GOXou/cuvr4VHPCJRSSp3P00oESimlCtFEoJRSHs5jEoGIXCkiO0Vkj4g8aXc8dhKR+iKyRES2i8hWEXnQ7pjsJiLeIrJRRL63Oxa7iUh1EZkrIjscfyPd7Y7JLiLysON/5E8R+UxE/O2OyRk8IhGIiDfwNjAUiAJGi0iUvVHZKgd4xBjTEugG3O/h1wPgQWC73UFUEG8APxljWgDt8NDrIiL1gMlAtDGmNeAN3GxvVM7hEYkA6ALsMcbEGmOygDnASJtjso0xJsEYs8HxOhXrH72evVHZR0TCgauBGXbHYjcRqQr0Ad4HMMZkGWNO2huVrXyAyiLiAwQAh22Oxyk8JRHUAw4WeB+PB9/4ChKRCKADsMbeSGz1OvA4kGd3IBVAJJAEfOCoKpshIoF2B2UHY8wh4GXgAJAApBhjfrE3KufwlEQgRSzz+HazIlIF+Ap4yBhzyu547CAiw4BEY8x6u2OpIHyAjsA7xpgOQBrgkc/URKQGVs1BI6AuECgit9gblXN4SiKIB+oXeB+OmxbxSkpEfLGSwGxjzNd2x2OjnsAIEYnDqjIcICKf2BuSreKBeGNMfglxLlZi8ESDgH3GmCRjTDbwNdDD5picwlMSwTqgqYg0EhE/rAc+822OyTYiIlh1wNuNMa/aHY+djDF/M8aEG2MisP4uFhtj3PJTX0kYY44AB0WkuWPRQGCbjSHZ6QDQTUQCHP8zA3HTB+c+dgdQHowxOSIyCfgZ68n/TGPMVpvDslNPYBzwh4hscix7yhizwMaYVMXxADDb8aEpFrjd5nhsYYxZIyJzgQ1YLe024qZDTegQE0op5eE8pWpIKaXUBWgiUEopD6eJQCmlPJwmAqWU8nCaCJRSysNpIlCqEBHJFZFNBb7KrGetiESIyJ9ldTylyoJH9CNQ6hKlG2Pa2x2EUuVFSwRKlZCIxInIiyKy1vHVxLG8oYgsEpEtju8NHMtricg3IrLZ8ZU/PIG3iPzPMc79LyJS2bYfSik0EShVlMqFqoZuKrDulDGmC/AW1qilOF5/ZIxpC8wGpjmWTwOWGWPaYY3Xk9+bvSnwtjGmFXASuN7JP49SxdKexUoVIiKnjTFVilgeBwwwxsQ6Bu07YowJFpFkoI4xJtuxPMEYEyIiSUC4MSazwDEigF+NMU0d758AfI0x/3b+T6ZU0bREoNSlMRd4faFtipJZ4HUu+qxO2UwTgVKX5qYC3393vF7FuSkMxwIrHa8XAffC2TmRq5ZXkEpdCv0kotT5KhcYlRWs+Xvzm5BWEpE1WB+iRjuWTQZmishjWLN75Y/W+SAwXUTuxPrkfy/WTFdKVSj6jECpEnI8I4g2xiTbHYtSZUmrhpRSysNpiUAppTyclgiUUsrDaSJQSikPp4lAKaU8nCYCpZTycJoIlFLKw/1/X6ypbbpyCBsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(g_loss)\n",
    "plt.plot(d_loss)\n",
    "plt.title('GAN Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Generator', 'Discriminator'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

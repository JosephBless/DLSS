{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "#If you are using Tensorflow 1.x\n",
    "from keras.optimizers import Adam\n",
    "#If you are using Tensorflow 2\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder containing dataset\n",
    "data_path = r'D:\\Downloads\\selfie2anime\\trainB'\n",
    "\n",
    "#how many epochs to run the model\n",
    "epoch = 10\n",
    "\n",
    "#how many epochs between saving your model\n",
    "interval = 2\n",
    "\n",
    "#how many images to train at one time. If batch size is less than 9, alter the save_img function to plot less images\n",
    "batch = 10\n",
    "\n",
    "#if the data has pngs set this to True to remove alpha layer from images\n",
    "png = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset from local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "        data = []\n",
    "        small = []\n",
    "        paths = []\n",
    "        #get all files in this folder\n",
    "        for r, d, f in os.walk(data_path):\n",
    "            for file in f:\n",
    "                if '.jpg' in file or 'png' in file:\n",
    "                    paths.append(os.path.join(r, file))\n",
    "        #for each file add normal resolution and low resolution to arrays\n",
    "        for path in paths:\n",
    "            img = Image.open(path)\n",
    "            x = np.array(img.resize((64,64)))\n",
    "            y = np.array(img.resize((256,256)))\n",
    "            if(png):\n",
    "                x = x[...,:3]\n",
    "            data.append(y)\n",
    "            small.append(x)\n",
    "            \n",
    "        #reshaping data to be four dimension required for input to neural network\n",
    "        y_train = np.array(data)\n",
    "        y_train = y_train.reshape(len(data),256,256,3)\n",
    "        x_train = np.array(small)\n",
    "        x_train = x_train.reshape(len(small),64,64,3)\n",
    "        del data\n",
    "        del small\n",
    "        del paths\n",
    "        return y_train, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Shape of high resolution output image\n",
    "        self.img_rows = 256\n",
    "        self.img_cols = 256\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        # Shape of low resolution input image\n",
    "        self.latent_dim = (64,64,3)\n",
    "\n",
    "        #optimizer (learning rate and beta values)\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        generator = self.generator\n",
    "\n",
    "        # The generator takes image as input and generates high resolution image\n",
    "        z = Input(shape=self.latent_dim)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, input_shape=self.latent_dim, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(64, kernel_size=(2,2), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(64, kernel_size=(2,2), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=(2,2), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(3, kernel_size=(5,5), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=self.latent_dim)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "    \n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        Y_train, X_train = load_data()\n",
    "\n",
    "        # Rescale to be between 0 & 1\n",
    "        X_train = X_train / 255\n",
    "        Y_train = Y_train / 255\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Placeholder for loss function values\n",
    "        g_loss_epochs = np.zeros((epochs, 1))\n",
    "        d_loss_epochs = np.zeros((epochs, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, Y_train.shape[0], batch_size)\n",
    "            imgs = Y_train[idx]\n",
    "\n",
    "            # Generate super resolution images from the random batch of images\n",
    "            gen_imgs = self.generator.predict(X_train[idx])\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(X_train[idx], valid)\n",
    "            \n",
    "            #save loss history\n",
    "            g_loss_epochs[epoch] = g_loss\n",
    "            d_loss_epochs[epoch] = d_loss[0]\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch, X_train, idx)\n",
    "            \n",
    "        return g_loss_epochs, d_loss_epochs\n",
    "\n",
    "    def save_imgs(self, epoch, X_train, idx):\n",
    "        r, c = 3, 3\n",
    "        # Select 9 random images\n",
    "        index = np.random.randint(0, X_train.shape[0], 9)\n",
    "        images = X_train[idx]\n",
    "        # Super resolution the images\n",
    "        gen_imgs = self.generator.predict(images)\n",
    "        gen_imgs = np.array(gen_imgs) * 255\n",
    "        gen_imgs = gen_imgs.astype(int)\n",
    "        # Plot each image\n",
    "        fig=plt.figure(figsize=(20, 20))\n",
    "        for i in range(1, c*r+1):\n",
    "            img = gen_imgs[i-1]\n",
    "            fig.add_subplot(r, c, i)\n",
    "            plt.imshow(img)\n",
    "        fig.savefig(\"epoch_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "        # save model to .h5 file\n",
    "        self.generator.save(\"generator\" + str(epoch) + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model and View Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 131073    \n",
      "=================================================================\n",
      "Total params: 224,321\n",
      "Trainable params: 224,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 64)        16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 128, 64)      16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 256, 256, 64)      16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 256, 256, 3)       4803      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 256, 256, 3)       0         \n",
      "=================================================================\n",
      "Total params: 240,579\n",
      "Trainable params: 240,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = SRGAN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.691173, acc.: 30.00%] [G loss: 0.692227]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 0.439801, acc.: 50.00%] [G loss: 0.670782]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [D loss: 0.422245, acc.: 50.00%] [G loss: 0.627513]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [D loss: 0.448176, acc.: 50.00%] [G loss: 0.718547]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [D loss: 0.336239, acc.: 100.00%] [G loss: 1.246036]\n",
      "5 [D loss: 0.346882, acc.: 100.00%] [G loss: 0.930536]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [D loss: 0.562044, acc.: 50.00%] [G loss: 0.558681]\n",
      "7 [D loss: 0.821598, acc.: 50.00%] [G loss: 0.466292]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [D loss: 0.935554, acc.: 50.00%] [G loss: 0.683131]\n",
      "9 [D loss: 0.767055, acc.: 50.00%] [G loss: 1.279757]\n"
     ]
    }
   ],
   "source": [
    "g_loss, d_loss = gan.train(epochs=epoch, batch_size=batch, save_interval=interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(g_loss)\n",
    "plt.plot(d_loss)\n",
    "plt.title('GAN Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Generator', 'Discriminator'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
